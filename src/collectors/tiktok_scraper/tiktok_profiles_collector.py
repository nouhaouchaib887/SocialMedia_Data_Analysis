import requests
import time
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Union


import requests
import time
import json
import os # Import os for checking file paths (optional but good practice)
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Union

# Define a custom exception for scraper errors
class TikTokScraperError(Exception):
    """Custom exception for TikTok Scraper errors."""
    pass

class TikTokProfileScraper:
    """
    Classe pour collecter les informations des profils TikTok
    via l'API Apify TikTok Profile Scraper
    """
    
    def __init__(self, apify_token: str):
        """
        Initialise le scraper avec le token Apify
        
        Args:
            apify_token (str): Token d'authentification Apify
            
        Raises:
            TikTokScraperError: Si le token n'est pas fourni.
        """
        if not apify_token:
             raise TikTokScraperError("Apify token is required.")
             
        self.apify_token = apify_token
        self.actor_id = 'clockworks~tiktok-profile-scraper'
        self.base_url = 'https://api.apify.com/v2'
        
    def _prepare_actor_input(self, 
                           profiles: List[str], 
                           results_per_page: int = 1) -> Dict:
        """
        Pr√©pare les param√®tres d'entr√©e pour l'actor Apify
        
        Args:
            profiles (List[str]): Liste des noms d'utilisateur TikTok
            results_per_page (int): Nombre de r√©sultats par page
            
        Returns:
            Dict: Param√®tres format√©s pour l'actor
        """  
        # Basic input validation
        if not isinstance(profiles, list) or not profiles:
             raise TikTokScraperError("Profiles must be a non-empty list of strings.")
        if not all(isinstance(p, str) for p in profiles):
             raise TikTokScraperError("All profile names must be strings.")
        if not isinstance(results_per_page, int) or results_per_page <= 0:
             print("‚ö†Ô∏è Warning: results_per_page should be a positive integer. Defaulting to 1.")
             results_per_page = 1 # Or raise an error depending on desired strictness

        actor_input = {
            "profiles": profiles,
            "resultsPerPage": results_per_page
        }
        
        return actor_input
    
    def _start_scraping_run(self, actor_input: Dict) -> str:
        """
        Lance une nouvelle ex√©cution du scraper
        
        Args:
            actor_input (Dict): Param√®tres d'entr√©e pour l'actor
            
        Returns:
            str: ID de l'ex√©cution
            
        Raises:
            TikTokScraperError: Si le lancement √©choue (network error, API error, invalid response)
        """
        print(f"üöÄ Lancement de l'actor {self.actor_id}...")
        url = f'{self.base_url}/acts/{self.actor_id}/runs?token={self.apify_token}'
        try:
            response = requests.post(url, json=actor_input)
            response.raise_for_status() # L√®ve une exception pour les codes 4xx ou 5xx
            
            run_data = response.json()
            run_id = run_data.get('data', {}).get('id')
            
            if not run_id:
                raise TikTokScraperError("Impossible de r√©cup√©rer l'ID du run dans la r√©ponse de l'API.")
                
            print(f"‚úÖ Scraper lanc√© avec l'ID: {run_id}")
            return run_id
            
        except requests.exceptions.RequestException as e:
            # Catch network errors, connection issues, HTTP errors
            error_msg = f"Erreur r√©seau ou API lors du lancement du scraper: {e}"
            if response is not None:
                error_msg += f" (Status Code: {response.status_code}, Response: {response.text[:200]}...)"
            raise TikTokScraperError(error_msg) from e
        except json.JSONDecodeError as e:
             raise TikTokScraperError(f"Erreur lors du d√©codage JSON de la r√©ponse de lancement: {e}") from e
        except Exception as e:
            # Catch any other unexpected errors
            raise TikTokScraperError(f"Une erreur inattendue s'est produite lors du lancement: {e}") from e
            
    def _wait_for_completion(self, run_id: str, timeout: int = 300, check_interval: int = 5) -> Dict:
        """
        Attend la fin de l'ex√©cution du scraper
        
        Args:
            run_id (str): ID de l'ex√©cution
            timeout (int): Timeout en secondes (d√©faut: 300s)
            check_interval (int): Intervalle de v√©rification en secondes (d√©faut: 5s)
            
        Returns:
            Dict: Donn√©es du statut final de l'ex√©cution
            
        Raises:
            TikTokScraperError: Si l'ex√©cution √©choue ou d√©passe le timeout
        """
        start_time = time.time()
        url = f'{self.base_url}/actor-runs/{run_id}?token={self.apify_token}'
        
        print("‚è≥ Attente de la fin de l'ex√©cution...")

        while True:
            elapsed_time = time.time() - start_time
            if elapsed_time > timeout:
                raise TikTokScraperError(f"Timeout d√©pass√© ({timeout}s) en attendant la fin de l'ex√©cution {run_id}")
                
            try:
                response = requests.get(url)
                response.raise_for_status() # L√®ve une exception pour les codes 4xx ou 5xx
                
                run_status_data = response.json().get('data', {})
                status = run_status_data.get('status')
                
                if not status:
                     print(f"‚ö†Ô∏è Warning: 'status' field missing in run status response for {run_id}.")
                     # Continue waiting, or potentially raise error after a few attempts

                print(f"üîÑ Statut actuel ({int(elapsed_time)}s): {status}")
                
                if status in ['SUCCEEDED', 'FAILED', 'ABORTED', 'TIMED-OUT']:
                    break
                    
            except requests.exceptions.RequestException as e:
                 print(f"‚ö†Ô∏è Warning: Erreur r√©seau ou API lors de la v√©rification du statut de {run_id}: {e}. R√©essai...")
                 # Don't re-raise immediately, maybe it's transient. Sleep and retry.
            except json.JSONDecodeError as e:
                 print(f"‚ö†Ô∏è Warning: Erreur JSON lors de la v√©rification du statut de {run_id}: {e}. R√©essai...")
                 # Sleep and retry
            except Exception as e:
                 # Catch other unexpected errors during status check
                 print(f"‚ö†Ô∏è Warning: Une erreur inattendue s'est produite lors de la v√©rification du statut de {run_id}: {e}. R√©essai...")
                 # Sleep and retry

            time.sleep(check_interval)
        
        if status != 'SUCCEEDED':
            raise TikTokScraperError(f"Le scraper a √©chou√© ou n'a pas r√©ussi. Statut final pour {run_id}: {status}")
            
        print(f"‚úÖ Ex√©cution {run_id} termin√©e avec succ√®s. Statut: {status}")
        return run_status_data
    
    def _fetch_dataset(self, dataset_id: str) -> List[Dict]:
        """
        R√©cup√®re les donn√©es du dataset
        
        Args:
            dataset_id (str): ID du dataset
            
        Returns:
            List[Dict]: Donn√©es brutes du dataset
            
        Raises:
            TikTokScraperError: Si la r√©cup√©ration √©choue
        """
        print(f"üì• R√©cup√©ration des donn√©es du dataset {dataset_id}...")
        url = f'{self.base_url}/datasets/{dataset_id}/items?token={self.apify_token}&clean=true'
        try:
            response = requests.get(url)
            response.raise_for_status() # L√®ve une exception pour les codes 4xx ou 5xx
            
            data = response.json()
            print(f"‚úÖ Donn√©es r√©cup√©r√©es avec succ√®s. Nombre d'√©l√©ments: {len(data)}")
            return data
            
        except requests.exceptions.RequestException as e:
            error_msg = f"Erreur r√©seau ou API lors de la r√©cup√©ration des donn√©es du dataset {dataset_id}: {e}"
            if response is not None:
                error_msg += f" (Status Code: {response.status_code}, Response: {response.text[:200]}...)"
            raise TikTokScraperError(error_msg) from e
        except json.JSONDecodeError as e:
            raise TikTokScraperError(f"Erreur lors du d√©codage JSON des donn√©es du dataset {dataset_id}: {e}") from e
        except Exception as e:
             raise TikTokScraperError(f"Une erreur inattendue s'est produite lors de la r√©cup√©ration des donn√©es du dataset {dataset_id}: {e}") from e

    
    def _safe_get_nested(self, data: Dict, *keys, default=None):
        """
        R√©cup√®re une valeur imbriqu√©e de mani√®re s√©curis√©e
        
        Args:
            data (Dict): Dictionnaire source
            *keys: Cl√©s imbriqu√©es
            default: Valeur par d√©faut
            
        Returns:
            Valeur trouv√©e ou valeur par d√©faut
        """
        if not isinstance(data, dict):
            return default # Handle cases where data is not even a dictionary
        
        try:
            value = data
            for key in keys:
                if isinstance(value, dict):
                    value = value.get(key, default)
                elif isinstance(value, list) and isinstance(key, int) and len(value) > key:
                    value = value[key] # Basic list index support if needed, though not used here
                else:
                    return default # Key not found or data is not a dict/list at this level
                
                if value is default and key != keys[-1]:
                     # If we got the default value *before* the last key, the path is broken
                     return default
                     
            return value
        except (TypeError, IndexError, AttributeError):
            # Catch potential errors if an intermediate step isn't a dict/list as expected
            return default

    def _transform_profile_data(self, raw_profile: Dict) -> Optional[Dict]:
        """
        Transforme les donn√©es brutes du profil en format standardis√©
        
        Args:
            raw_profile (Dict): Donn√©es brutes du profil
            
        Returns:
            Optional[Dict]: Profil format√© ou None si les donn√©es brutes sont insuffisantes/invalides
        """
        if not isinstance(raw_profile, dict) or not raw_profile:
             print(f"‚ö†Ô∏è Skipping invalid raw profile data: {raw_profile}")
             return None
             
        author_meta = raw_profile.get("authorMeta", {})
        if not author_meta:
             print(f"‚ö†Ô∏è Skipping profile data with missing 'authorMeta': {raw_profile}")
             return None

        # Check for essential fields
        profile_id = self._safe_get_nested(author_meta, "id")
        profile_name = self._safe_get_nested(author_meta, "nickName")
        if not profile_id or not profile_name:
             print(f"‚ö†Ô∏è Skipping profile with missing ID or Nickname: {raw_profile}")
             return None

        transformed_data = {
            "platform": "tiktok",
            "profile_id": profile_id,
            "profile_name": profile_name,
            "page_name": self._safe_get_nested(author_meta, "name", ""), # Ensure default is same type
            "url": self._safe_get_nested(author_meta, "profileUrl", ""),
            "biography": self._safe_get_nested(author_meta, "signature", ""),
            "metrics": {
                "likes": self._safe_get_nested(author_meta, "heart", 0),
                "followers": self._safe_get_nested(author_meta, "fans", 0),
                # Add other metrics if available and needed, e.g., videoCount
                "video_count": self._safe_get_nested(author_meta, "video", 0),
            },
            "is_verified": self._safe_get_nested(author_meta, "verified", False),
            "scraped_at": datetime.now().isoformat()
        }
        
        return transformed_data
    
    def scrape_profiles(self, 
                       profiles: Union[str, List[str]], 
                       results_per_page: int = 1,
                       timeout: int = 300, 
                       save_to_file: Optional[str] = None) -> List[Dict]:
        """
        Scrape les profils TikTok sp√©cifi√©s
        
        Args:
            profiles (Union[str, List[str]]): Nom d'utilisateur ou liste de noms d'utilisateur
            results_per_page (int): Nombre de r√©sultats par page
            timeout (int): Timeout en secondes pour l'ex√©cution
            save_to_file (Optional[str]): Chemin du fichier de sauvegarde (optionnel)
            
        Returns:
            List[Dict]: Liste des profils scrap√©s et format√©s
            
        Raises:
            TikTokScraperError: Si le processus de scraping √©choue √† une √©tape critique.
        """
        # Convertir en liste si c'est une cha√Æne
        if isinstance(profiles, str):
            profiles = [profiles]
            
        # Input validation handled in _prepare_actor_input
        
        tiktok_profiles = []
        run_id = None # Initialize run_id outside try block
        
        try:
            # 1. Pr√©parer les param√®tres (validation incluse)
            actor_input = self._prepare_actor_input(
                profiles=profiles,
                results_per_page=results_per_page
            )
            
            # 2. Lancer le scraper
            run_id = self._start_scraping_run(actor_input)
            
            # 3. Attendre la fin
            run_status_data = self._wait_for_completion(run_id, timeout)
            
            # 4. R√©cup√©rer les donn√©es
            dataset_id = run_status_data.get('defaultDatasetId')
            if not dataset_id:
                raise TikTokScraperError(f"Impossible de r√©cup√©rer l'ID du dataset pour l'ex√©cution {run_id}. Aucune donn√©e disponible.")
                
            raw_data = self._fetch_dataset(dataset_id)
            
            # 5. Transformer les donn√©es
            print("‚ú® Transformation des donn√©es des profils...")
            for i, raw_profile in enumerate(raw_data):
                try:
                    transformed_profile = self._transform_profile_data(raw_profile)
                    if transformed_profile: # Only add if transformation was successful
                        tiktok_profiles.append(transformed_profile)
                except Exception as e:
                    # Catch unexpected errors during transformation of a single profile
                    print(f"‚ö†Ô∏è Erreur lors de la transformation du profil {i+1}: {e}. Skipping this profile.")
                    # Continue with the next profile
                    
            print(f"‚úÖ {len(tiktok_profiles)} profil(s) TikTok trait√©(s) avec succ√®s sur {len(raw_data)} √©l√©ments bruts.")
            
            # 6. Sauvegarder si demand√©
            if save_to_file:
                self.save_profiles(tiktok_profiles, save_to_file)
                
        except TikTokScraperError as e:
            # Catch exceptions raised by helper methods
            print(f"‚ùå Une erreur est survenue pendant le processus de scraping: {e}")
            # Depending on requirement, you might want to return partial results or an empty list
            # For now, we re-raise or return empty based on severity. Let's return empty.
            return [] # Indicate failure by returning an empty list

        except Exception as e:
            # Catch any other unexpected exceptions during the orchestration
            print(f"‚ùå Une erreur inattendue est survenue dans scrape_profiles: {e}")
            # You might want to inspect the run on Apify if run_id is available
            if run_id:
                print(f"Veuillez v√©rifier l'√©tat de l'ex√©cution Apify {run_id} pour plus de d√©tails.")
            return [] # Indicate failure

        return tiktok_profiles
    
    def save_profiles(self, profiles: List[Dict], filename: str) -> None:
        """
        Sauvegarde les profils dans un fichier JSON
        
        Args:
            profiles (List[Dict]): Liste des profils √† sauvegarder
            filename (str): Nom du fichier de sauvegarde
            
        Raises:
            TikTokScraperError: Si la sauvegarde √©choue.
        """
        if not filename:
             raise TikTokScraperError("Filename for saving cannot be empty.")
             
        try:
            # Ensure directory exists if filename contains a path
            dirname = os.path.dirname(filename)
            if dirname and not os.path.exists(dirname):
                 os.makedirs(dirname)
                 print(f"üìÇ Cr√©ation du r√©pertoire: {dirname}")
                 
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(profiles, f, ensure_ascii=False, indent=2)
            print(f"üíæ Profils TikTok sauvegard√©s dans '{filename}'")
            
        except (IOError, OSError) as e:
            raise TikTokScraperError(f"Erreur lors de la sauvegarde du fichier '{filename}': {e}") from e
        except TypeError as e:
             raise TikTokScraperError(f"Erreur de type lors de la s√©rialisation JSON du fichier '{filename}': {e}. Les donn√©es ne sont peut-√™tre pas JSON s√©rialisables.") from e
        except Exception as e:
             raise TikTokScraperError(f"Une erreur inattendue s'est produite lors de la sauvegarde du fichier '{filename}': {e}") from e


    def get_profiles_summary(self, profiles: List[Dict]) -> None:
        """
        Affiche un r√©sum√© des profils TikTok scrap√©s
        
        Args:
            profiles (List[Dict]): Liste des profils
        """
        if not profiles:
            print("\nPas de profils √† afficher.")
            return

        print("\nüìä R√âSUM√â DES PROFILS TIKTOK:")
        print("=" * 60)
        
        for profile in profiles:
            # Use _safe_get_nested or .get() for robustness, though data should be clean here
            profile_name = self._safe_get_nested(profile, 'profile_name', 'N/A')
            profile_id = self._safe_get_nested(profile, 'profile_id', 'N/A')
            url = self._safe_get_nested(profile, 'url', 'N/A')
            followers = self._safe_get_nested(profile, 'metrics', 'followers', 0)
            likes = self._safe_get_nested(profile, 'metrics', 'likes', 0)
            is_verified = self._safe_get_nested(profile, 'is_verified', False)
            biography = self._safe_get_nested(profile, 'biography', '')

            if profile_name != 'N/A':
                print(f"   üìù Nom d'affichage: {profile_name}")
            if profile_id != 'N/A':
                 print(f"   üÜî ID: {profile_id}")
            if url != 'N/A':
                print(f"   üîó URL: {url}")
            print(f"   üë• Followers: {followers:,}") # Use :, for comma formatting
            print(f"   üíñ Likes totaux: {likes:,}")
            print(f"   ‚úÖ V√©rifi√©: {'Oui' if is_verified else 'Non'}")
            if biography:
                bio_preview = biography[:80] + "..." if len(biography) > 80 else biography
                print(f"   üìÑ Bio: {bio_preview}")
            print("-" * 60)
    
    def scrape_telecom_profiles(self, 
                              # oldest_post_date is not supported by this Apify actor input,
                              # so let's remove it or note it if it were relevant for other actors
                              # oldest_post_date: Optional[str] = None, 
                              save_to_file: Optional[str] = None,
                              timeout: int = 300) -> List[Dict]:
        """
        M√©thode de convenance pour scraper les profils TikTok des op√©rateurs t√©l√©coms marocains
        
        Args:
            # oldest_post_date (Optional[str]): Date la plus ancienne (YYYY-MM-DD) - Not applicable for this actor
            save_to_file (Optional[str]): Fichier de sauvegarde
            timeout (int): Timeout en secondes pour l'ex√©cution
            
        Returns:
            List[Dict]: Profils des op√©rateurs t√©l√©coms (peut √™tre vide en cas d'erreur)
        """
        telecom_profiles = [
            "orangemaroc",
            "inwi.maroc", 
            "maroctelecom"
        ]
        
        print("\nü§ñ Lancement du scraping pour les profils t√©l√©coms marocains...")

        # Note: results_per_page=1 is sufficient for just getting profile info,
        # as the actor returns only one item per profile requested in the 'profiles' list.
        return self.scrape_profiles(
            profiles=telecom_profiles,
            results_per_page=1, # This actor input seems to control video results, not profile count per se
            timeout=timeout,
            save_to_file=save_to_file
            # oldest_post_date=oldest_post_date # Remove this as it's not a valid input for this actor
        )
